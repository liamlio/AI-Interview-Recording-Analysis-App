{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e30a1c5-a740-4793-addd-7743b1e7a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import utils\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "AAI_API_KEY = os.getenv(\"AAI_API_KEY\")\n",
    "\n",
    "def transcribe(audio_file):\n",
    "    if AAI_API_KEY is None:\n",
    "        raise RuntimeError(\"AAI_API_KEY environment variable not set. Try setting it now.\")\n",
    "\n",
    "    # Create header with authorization along with content-type\n",
    "    header = {\n",
    "        'authorization': AAI_API_KEY,\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "\n",
    "    upload_url = utils.upload_file(audio_file, header)\n",
    "\n",
    "    # Request a transcription\n",
    "    transcript_response = utils.request_transcript(upload_url, header)\n",
    "\n",
    "    # Create a polling endpoint that will let us check when the transcription is complete\n",
    "    polling_endpoint = utils.make_polling_endpoint(transcript_response)\n",
    "\n",
    "    # Wait until the transcription is complete\n",
    "    while True:\n",
    "        polling_response = requests.get(polling_endpoint, headers=header)\n",
    "        polling_response = polling_response.json()\n",
    "\n",
    "        if polling_response['status'] == 'completed':\n",
    "            break\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    # Save and print transcript\n",
    "    with open('transcript.json', 'w') as f:\n",
    "        f = json.dumps(polling_response)\n",
    "\n",
    "    return polling_response, polling_endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16aa4796-b609-4a6f-ad10-a2f236b75fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "        'authorization': AAI_API_KEY,\n",
    "        'content-type': 'application/json'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f245e2-80ba-4958-8ae0-1d3b9b9d364d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transcript_response, polling_endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maudio.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m polling_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Save and print transcript\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscript.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transcript_response, polling_endpoint = transcribe('audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ab3130-d66c-4078-8251-5ae24d759864",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = utils.get_paragraphs(polling_endpoint, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c58c0a-c72d-446f-ae67-782a8c921c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI is a deep learning company that builds powerful APIs to help you transcribe and understand audio. The most common use case for the API is to automatically convert prerecorded audio and video files, as well as real time audio streams into text transcriptions. Our APIs convert audio and video into text using powerful deep learning models that we research and develop end to end in house. Millions of podcasts, zoom recordings, phone calls, or video files are being transcribed with AssemblyAI every single day. But where AssemblyAI really excels is with helping you understand your data.\n",
      "So let's say we transcribe Joe Biden's State of the Union using assembly. AI's API. With our Auto Chapter feature, you can generate time coded summaries of the key moments of your audio file. For example, with the State of the Union address, we get chapter summaries like this auto Chapters automatically segments your audio or video files into chapters and provides a summary for each of these chapters. With sentiment analysis, we can classify what's being spoken in your audio files as either positive, negative, or neutral.\n",
      "So, for example, in the State of the Union address, we see that this sentence was classified as positive, whereas this sentence was classified as negative. Content Safety Detection can flag sensitive content as it is spoken, like hate speech, profanity, violence, or weapons. For example, in Biden's State of the Union address, content safety detection flags parts of his speech as being about weapons. This feature is especially useful for automatic content moderation and brand safety use cases. With Auto highlights, you can automatically identify important words and phrases that are being spoken in your data.\n",
      "Owned by the State of the Union address, Assembly AI's API detected these words and phrases as being important. Lastly, with entity detection, you can identify entities that are spoken in your audio, like organization names or person names. In Biden's speech, these were the entities that were detected. This is just a preview of the most popular features of AssemblyAI API. If you want a full list of features, go check out our API's documentation linked in the description below.\n",
      "And if you ever need some support, our team of developers is here to help. Everyday developers are using these features to build really exciting applications. From meeting summarizers, to brand safety or contextual targeting platforms, to fullblown conversational intelligence tools, we can't wait to see what you build with AssemblyAI.\n"
     ]
    }
   ],
   "source": [
    "for p in paragraphs:\n",
    "    print(p['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60e66a3-0e44-4c08-863c-52a6144eb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "co = cohere.Client(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b12611e4-7c79-4f4f-9f24-cc9092a85307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def create_embeds(texts, user_id=\"test\"):\n",
    "    texts = sent_tokenize(texts)\n",
    "    embeds = co.embed(texts, model=\"large\", truncate=\"right\")\n",
    "    return texts, embeds\n",
    "texts = \" \".join([p[\"text\"] for p in paragraphs])\n",
    "texts, embeds = create_embeds(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829dab74-f59d-4374-9e65-71b37ab9dcff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeds.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05efecfb-7fe0-4fc1-a903-b05865beb585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"valhalla/distilbart-mnli-12-1\")\n",
    "built_ins = [\"entrepreneurship\", \"confidence\", \"Growth Mindset\"]\n",
    "\n",
    "def score_BART_text(text, model_name):\n",
    "    pred = classifier(text, [model_name, \"not \" + model_name ])\n",
    "    if pred[model_name] > pred[\"not \" + model_name]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def score_CUSTOM_text(text_embed, custom_model_embeds):\n",
    "    mean_score = np.mean([cosine(e, text_embed) for e in custom_model_embeds.embeddings])\n",
    "    if len(custom_model_embeds.embeddings) < 5:\n",
    "        threshold = 1.0 - len(custom_model_embeds.embeddings) / 10\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    if mean_score > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2262988c-b36e-4284-802f-b39cbf85e139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prefilled_models = {\n",
    "    \"Craftpersonship\": \"Find meaning in what we do through crafting excellence.\",\n",
    "    \"Playfulness\": \"Great ideas come from health and happiness.\",\n",
    "    \"Grit\": \"Perseverance driven by determination and passion.\",\n",
    "    \"Empathy\": \"Innovation starts with understanding.\",\n",
    "    \"Zest\": \"What sets you apart makes us unique.\",\n",
    "    \"Courage\": \"Dare often and greatly.\"\n",
    "}\n",
    "texts_df = pd.DataFrame({\"text\":texts, \"embeddings\": embeds.embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aefc7507-73ad-43ad-8252-e9cc1fda6626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>craftpersonship</th>\n",
       "      <th>Playfulness</th>\n",
       "      <th>Grit</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>Zest</th>\n",
       "      <th>Courage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AssemblyAI is a deep learning company that bui...</td>\n",
       "      <td>[1.3828125, 0.28051758, 1.9667969, -1.0039062,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The most common use case for the API is to aut...</td>\n",
       "      <td>[0.35839844, 1.578125, 2.1542969, 0.91064453, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our APIs convert audio and video into text usi...</td>\n",
       "      <td>[0.7441406, 0.6464844, 1.5029297, -1.5751953, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Millions of podcasts, zoom recordings, phone c...</td>\n",
       "      <td>[0.24597168, 1.2382812, 2.2871094, 0.37695312,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But where AssemblyAI really excels is with hel...</td>\n",
       "      <td>[1.0498047, 1.7324219, 1.7011719, -0.0770874, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  AssemblyAI is a deep learning company that bui...   \n",
       "1  The most common use case for the API is to aut...   \n",
       "2  Our APIs convert audio and video into text usi...   \n",
       "3  Millions of podcasts, zoom recordings, phone c...   \n",
       "4  But where AssemblyAI really excels is with hel...   \n",
       "\n",
       "                                          embeddings  craftpersonship  \\\n",
       "0  [1.3828125, 0.28051758, 1.9667969, -1.0039062,...                0   \n",
       "1  [0.35839844, 1.578125, 2.1542969, 0.91064453, ...                1   \n",
       "2  [0.7441406, 0.6464844, 1.5029297, -1.5751953, ...                0   \n",
       "3  [0.24597168, 1.2382812, 2.2871094, 0.37695312,...                0   \n",
       "4  [1.0498047, 1.7324219, 1.7011719, -0.0770874, ...                0   \n",
       "\n",
       "   Playfulness  Grit  Empathy  Zest  Courage  \n",
       "0            1     0        0     0        0  \n",
       "1            1     1        1     1        1  \n",
       "2            0     0        0     0        0  \n",
       "3            0     1        0     0        0  \n",
       "4            0     0        0     0        0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_custom_models(text_df, customs_models=prefilled_models):\n",
    "    for model_name in custom_models:\n",
    "        _, embeds_custom = create_embeds(custom_models[model_name], user_id=\"test\")\n",
    "        texts_df[model_name] = texts_df[\"embeddings\"].apply(lambda x: score_CUSTOM_text(x, embeds_custom))\n",
    "        time.sleep(10) #Throttle since we're using the free tier for cohere\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "287a1e1f-b338-4c95-b95c-34a645d94068",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'entrepreneurship'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m built_ins:\n\u001b[1;32m----> 2\u001b[0m      texts_df[model] \u001b[38;5;241m=\u001b[39m \u001b[43mtexts_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_BART_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m built_ins:\n\u001b[1;32m----> 2\u001b[0m      texts_df[model] \u001b[38;5;241m=\u001b[39m texts_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mscore_BART_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[58], line 10\u001b[0m, in \u001b[0;36mscore_BART_text\u001b[1;34m(text, model_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_BART_text\u001b[39m(text, model_name):\n\u001b[0;32m      9\u001b[0m     pred \u001b[38;5;241m=\u001b[39m classifier(text, [model_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name ])\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name]:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'entrepreneurship'"
     ]
    }
   ],
   "source": [
    "for model in built_ins:\n",
    "     texts_df[model] = texts_df[\"text\"].apply(lambda x: score_BART_text(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e590e-f392-4a16-bb03-3b61d8929a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier(texts, [model_name, \"not \" + model_name ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
